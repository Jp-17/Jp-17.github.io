---
layout: default
title: About
---

<div class="about-header">
  <img class="about-photo" src="{{ '/images/me1.jpg' | relative_url }}" alt="Peng Jiang">
  <div class="about-intro">
    <h1>Peng Jiang <span style="color:var(--fg-muted);font-weight:400;font-size:0.9rem;">蒋鹏</span></h1>
    <p class="subtitle">PhD Student, Computational Neuroscience · Tsinghua University</p>
    <div class="contacts">
      <a href="mailto:jiang-p21@mails.tsinghua.edu.cn">✉ jiang-p21@mails.tsinghua.edu.cn</a>
      <a href="https://github.com/Jp-17" target="_blank">GitHub</a>
      <a href="https://x.com/jiangp21" target="_blank">X / Twitter</a>
    </div>
  </div>
</div>

<section>
  <h2>About</h2>
  <p>
    I'm a PhD student in Computational Neuroscience at Tsinghua University, Beijing,
    supervised by <a href="https://jiaxx.github.io/">Prof. Xiaoxuan Jia</a> in the
    <a href="https://jiaxx.github.io/">Neural Coding Lab</a>.
    My work sits at the intersection of neuroscience and AI, asking how intelligent
    systems — brains and models alike — represent, reuse, and generalize knowledge.
  </p>
  <p>
    Currently I am working on <strong>Brain Foundation Model</strong> research —
    building large-scale pre-trained models for neural spiking data that can generalize
    across sessions, subjects, and brain regions. A central goal is to understand
    <strong>neural encoding</strong> mechanisms across modalities, and to leverage
    the learned universal representations for <strong>brain decoding</strong> tasks
    such as reconstructing perceived images and videos from neural activity.
    I am also deeply interested in <strong>real-time interactive digital humans</strong>
    and continue to explore this direction in parallel.
  </p>
</section>

<section>
  <h2>Research Interests</h2>
  <div class="interests">
    <span class="interest-tag">Brain Foundation Model</span>
    <span class="interest-tag">Brain Encoding &amp; Decoding</span>
    <span class="interest-tag">Real-time Interactive Digital Human</span>
    <span class="interest-tag">World Model</span>
    <span class="interest-tag">Neural Representation</span>
  </div>
</section>

<section>
  <h2>Education</h2>
  <div class="timeline">
    <div class="timeline-item">
      <div class="timeline-date">2021 – present</div>
      <div class="timeline-body">
        <h3>PhD, Computational Neuroscience</h3>
        <p class="org">Tsinghua University &nbsp;·&nbsp; Supervisor: <a href="https://jiaxx.github.io/">Prof. Xiaoxuan Jia</a></p>
      </div>
    </div>
    <div class="timeline-item">
      <div class="timeline-date">2017 – 2021</div>
      <div class="timeline-body">
        <h3>B.Sc., Life Sciences &nbsp;<span style="font-weight:400;color:var(--fg-muted);">(Minor: Computer Science)</span></h3>
        <p class="org">Tsinghua University</p>
      </div>
    </div>
  </div>
</section>

<section>
  <h2>Academic Experience</h2>
  <div class="timeline">
    <div class="timeline-item">
      <div class="timeline-date">2022 – 2024</div>
      <div class="timeline-body">
        <h3>Multi-task Neural Representation Research</h3>
        <p class="org">Neural Coding Lab, Tsinghua University</p>
        <ul>
          <li>Analyzed multi-task neural representations across brain regions using invasive Neuropixels recordings from mice</li>
          <li>Built multi-area RNN models to study hierarchical task representation in flexible cognition</li>
          <li>Investigated compositional generalization of task representations via continual learning with LoRA fine-tuning of LLMs</li>
        </ul>
      </div>
    </div>
  </div>
</section>

<section>
  <h2>Entrepreneurship</h2>
  <div class="timeline">
    <div class="timeline-item">
      <div class="timeline-date">2024 – 2025</div>
      <div class="timeline-body">
        <h3>Co-Founder &amp; Algorithm Lead</h3>
        <p class="org">Startup · Leave of absence from PhD</p>
        <p>
          I took a leave of absence to co-found a startup building a real-time,
          audio-driven interactive digital human system based on
          3D Gaussian Splatting (3DGS). We developed the full pipeline —
          from multi-camera capture &amp; calibration to 3DGS-based head
          reconstruction and diffusion-based audio-to-expression driving.
        </p>
      </div>
    </div>
  </div>
</section>

<section>
  <h2>Now</h2>
  <p>
    After returning to school in early 2026, I am focusing on
    <strong>Brain Foundation Model</strong> research — building large-scale pre-trained
    models for neural spiking data that generalize across sessions, subjects, and
    brain regions.
  </p>
  <p>
    The core ambition is twofold. On the <strong>encoding</strong> side, I want to
    understand how the brain encodes multimodal information: what representations
    emerge across different brain regions, how they are structured, and what
    computational principles unify them. On the <strong>decoding</strong> side, I
    believe that universal neural representations learned during pre-training can
    serve as a strong foundation for visual decoding tasks — reconstructing the images
    and videos a subject is perceiving directly from their neural activity.
    Together, these two directions form a coherent loop: encoding teaches the model
    the brain's language; decoding proves that the model has truly understood it.
  </p>
  <p>
    I remain deeply interested in real-time interactive digital humans
    and continue exploring this direction in parallel.
  </p>
</section>
